{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57a86445",
   "metadata": {},
   "source": [
    "# AI 머신러닝 4일차 학습 노트\n",
    "\n",
    "## 학습 목표\n",
    "- 1일차: Python & NumPy 기초 및 벡터화 연산\n",
    "- 2일차: Pandas 데이터 분석 및 시각화\n",
    "- 3일차: Scikit-Learn 기초 (회귀 모델)\n",
    "- 4일차: Scikit-Learn 심화 (앙상블 및 하이퍼파라미터 튜닝)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dc969b",
   "metadata": {},
   "source": [
    "# 1일차: Python & NumPy\n",
    "\n",
    "## 학습 내용\n",
    "- AI 전용 파이썬 문법 (List Comprehension, Decorator)\n",
    "- NumPy 메모리 구조 이해\n",
    "- 벡터화 연산(Vectorization)을 통한 성능 최적화\n",
    "- 행렬 연산 실습\n",
    "- for문 vs NumPy 속도 비교\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9870ab",
   "metadata": {},
   "source": [
    "## 1-1. List Comprehension (리스트 컴프리헨션)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bb1474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일반적인 for문\n",
    "squares = []\n",
    "for i in range(10):\n",
    "    squares.append(i**2)\n",
    "print(\"일반 for문:\", squares)\n",
    "\n",
    "# List Comprehension 사용\n",
    "squares_lc = [i**2 for i in range(10)]\n",
    "print(\"List Comprehension:\", squares_lc)\n",
    "\n",
    "# 조건문 포함\n",
    "even_squares = [i**2 for i in range(10) if i % 2 == 0]\n",
    "print(\"짝수 제곱:\", even_squares)\n",
    "\n",
    "# 중첩 List Comprehension\n",
    "matrix = [[i*j for j in range(3)] for i in range(3)]\n",
    "print(\"행렬:\", matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e1ec74",
   "metadata": {},
   "source": [
    "## 1-2. Decorator (데코레이터)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0140a71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# 데코레이터 예제: 함수 실행 시간 측정\n",
    "def timer_decorator(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end = time.time()\n",
    "        print(f\"{func.__name__} 실행 시간: {end - start:.4f}초\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "@timer_decorator\n",
    "def slow_function(n):\n",
    "    total = 0\n",
    "    for i in range(n):\n",
    "        total += i\n",
    "    return total\n",
    "\n",
    "result = slow_function(1000000)\n",
    "print(f\"결과: {result}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7358f34",
   "metadata": {},
   "source": [
    "## 1-3. NumPy 기초 및 메모리 구조\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3369e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# NumPy 배열 생성\n",
    "arr1 = np.array([1, 2, 3, 4, 5])\n",
    "arr2 = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "print(\"1차원 배열:\", arr1)\n",
    "print(\"2차원 배열:\\n\", arr2)\n",
    "print(\"배열 형태:\", arr2.shape)\n",
    "print(\"배열 차원:\", arr2.ndim)\n",
    "print(\"데이터 타입:\", arr2.dtype)\n",
    "print(\"메모리 크기:\", arr2.nbytes, \"bytes\")\n",
    "\n",
    "# 메모리 구조 확인\n",
    "print(\"\\n메모리 주소:\", arr2.data)\n",
    "print(\"연속 메모리:\", arr2.flags['C_CONTIGUOUS'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85283d92",
   "metadata": {},
   "source": [
    "## 1-4. 벡터화 연산 (Vectorization)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c32ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터화 연산 예제\n",
    "a = np.array([1, 2, 3, 4, 5])\n",
    "b = np.array([6, 7, 8, 9, 10])\n",
    "\n",
    "# 벡터화된 연산 (매우 빠름)\n",
    "result = a + b\n",
    "print(\"벡터 덧셈:\", result)\n",
    "\n",
    "result = a * b\n",
    "print(\"벡터 곱셈:\", result)\n",
    "\n",
    "result = np.sin(a)\n",
    "print(\"sin 함수:\", result)\n",
    "\n",
    "# 브로드캐스팅\n",
    "matrix = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "scalar = 10\n",
    "result = matrix * scalar\n",
    "print(\"\\n브로드캐스팅:\\n\", result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a888d823",
   "metadata": {},
   "source": [
    "## 1-5. 행렬 연산 실습\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1fa88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 행렬 생성\n",
    "A = np.array([[1, 2], [3, 4]])\n",
    "B = np.array([[5, 6], [7, 8]])\n",
    "\n",
    "print(\"행렬 A:\\n\", A)\n",
    "print(\"행렬 B:\\n\", B)\n",
    "\n",
    "# 행렬 곱셈\n",
    "C = np.dot(A, B)\n",
    "print(\"\\n행렬 곱셈 (A @ B):\\n\", C)\n",
    "\n",
    "# 전치 행렬\n",
    "A_T = A.T\n",
    "print(\"\\nA의 전치:\\n\", A_T)\n",
    "\n",
    "# 역행렬\n",
    "A_inv = np.linalg.inv(A)\n",
    "print(\"\\nA의 역행렬:\\n\", A_inv)\n",
    "\n",
    "# 행렬식\n",
    "det = np.linalg.det(A)\n",
    "print(\"\\nA의 행렬식:\", det)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d24652",
   "metadata": {},
   "source": [
    "## 1-6. for문 vs NumPy 속도 비교 (산출물)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e002172e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# 비교할 배열 크기\n",
    "size = 1000000\n",
    "\n",
    "# Python 리스트로 연산\n",
    "python_list1 = list(range(size))\n",
    "python_list2 = list(range(size))\n",
    "\n",
    "start = time.time()\n",
    "python_result = [python_list1[i] + python_list2[i] for i in range(size)]\n",
    "python_time = time.time() - start\n",
    "\n",
    "# NumPy 배열로 연산\n",
    "numpy_arr1 = np.array(range(size))\n",
    "numpy_arr2 = np.array(range(size))\n",
    "\n",
    "start = time.time()\n",
    "numpy_result = numpy_arr1 + numpy_arr2\n",
    "numpy_time = time.time() - start\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"배열 크기: {size:,}\")\n",
    "print(f\"Python 리스트 시간: {python_time:.4f}초\")\n",
    "print(f\"NumPy 배열 시간: {numpy_time:.4f}초\")\n",
    "print(f\"속도 향상: {python_time / numpy_time:.2f}배 빠름\")\n",
    "\n",
    "# 결과 비교\n",
    "print(f\"\\n결과 일치 여부: {sum(python_result[:10]) == numpy_result[:10].sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88191966",
   "metadata": {},
   "source": [
    "# 2일차: Pandas 데이터 분석\n",
    "\n",
    "## 학습 내용\n",
    "- DataFrame 조작\n",
    "- 결측치(Null) 처리\n",
    "- 복잡한 데이터 병합(Merge)\n",
    "- 시각화(Matplotlib)를 통한 데이터 분포 분석\n",
    "- 특성 추출(Feature Engineering)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349f228e",
   "metadata": {},
   "source": [
    "## 2-1. DataFrame 조작\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd28eef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# DataFrame 생성\n",
    "data = {\n",
    "    '이름': ['김철수', '이영희', '박민수', '최지영'],\n",
    "    '나이': [25, 30, 35, 28],\n",
    "    '직업': ['개발자', '디자이너', '개발자', '마케터'],\n",
    "    '급여': [5000, 4500, 6000, 4800]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"원본 DataFrame:\")\n",
    "print(df)\n",
    "print(\"\\n기본 정보:\")\n",
    "print(df.info())\n",
    "print(\"\\n기본 통계:\")\n",
    "print(df.describe())\n",
    "\n",
    "# 데이터 선택\n",
    "print(\"\\n특정 열 선택:\")\n",
    "print(df[['이름', '급여']])\n",
    "print(\"\\n조건 필터링 (급여 > 5000):\")\n",
    "print(df[df['급여'] > 5000])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e20a57c",
   "metadata": {},
   "source": [
    "## 2-2. 결측치(Null) 처리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b31756d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치가 있는 데이터 생성\n",
    "data_with_null = {\n",
    "    '이름': ['김철수', '이영희', '박민수', '최지영', '정수진'],\n",
    "    '나이': [25, None, 35, 28, None],\n",
    "    '직업': ['개발자', '디자이너', None, '마케터', '개발자'],\n",
    "    '급여': [5000, 4500, None, 4800, 5200]\n",
    "}\n",
    "df_null = pd.DataFrame(data_with_null)\n",
    "\n",
    "print(\"결측치가 있는 DataFrame:\")\n",
    "print(df_null)\n",
    "print(\"\\n결측치 확인:\")\n",
    "print(df_null.isnull())\n",
    "print(\"\\n결측치 개수:\")\n",
    "print(df_null.isnull().sum())\n",
    "\n",
    "# 결측치 처리 방법들\n",
    "print(\"\\n=== 결측치 처리 방법 ===\")\n",
    "\n",
    "# 1. 결측치 제거\n",
    "df_drop = df_null.dropna()\n",
    "print(\"\\n1. 결측치 제거:\")\n",
    "print(df_drop)\n",
    "\n",
    "# 2. 결측치를 평균으로 대체\n",
    "df_fill_mean = df_null.copy()\n",
    "df_fill_mean['나이'].fillna(df_fill_mean['나이'].mean(), inplace=True)\n",
    "print(\"\\n2. 나이 결측치를 평균으로 대체:\")\n",
    "print(df_fill_mean)\n",
    "\n",
    "# 3. 결측치를 특정 값으로 대체\n",
    "df_fill_value = df_null.copy()\n",
    "df_fill_value['직업'].fillna('미정', inplace=True)\n",
    "print(\"\\n3. 직업 결측치를 '미정'으로 대체:\")\n",
    "print(df_fill_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83babb6c",
   "metadata": {},
   "source": [
    "## 2-3. 데이터 병합(Merge)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a3106b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 병합할 데이터프레임 생성\n",
    "df1 = pd.DataFrame({\n",
    "    'ID': [1, 2, 3, 4],\n",
    "    '이름': ['김철수', '이영희', '박민수', '최지영'],\n",
    "    '부서': ['개발팀', '디자인팀', '개발팀', '마케팅팀']\n",
    "})\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    'ID': [1, 2, 3, 5],\n",
    "    '급여': [5000, 4500, 6000, 5500],\n",
    "    '입사일': ['2020-01-01', '2019-05-15', '2021-03-20', '2020-07-10']\n",
    "})\n",
    "\n",
    "print(\"DataFrame 1:\")\n",
    "print(df1)\n",
    "print(\"\\nDataFrame 2:\")\n",
    "print(df2)\n",
    "\n",
    "# Inner Join\n",
    "print(\"\\n=== Inner Join ===\")\n",
    "df_inner = pd.merge(df1, df2, on='ID', how='inner')\n",
    "print(df_inner)\n",
    "\n",
    "# Left Join\n",
    "print(\"\\n=== Left Join ===\")\n",
    "df_left = pd.merge(df1, df2, on='ID', how='left')\n",
    "print(df_left)\n",
    "\n",
    "# Outer Join\n",
    "print(\"\\n=== Outer Join ===\")\n",
    "df_outer = pd.merge(df1, df2, on='ID', how='outer')\n",
    "print(df_outer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a47774",
   "metadata": {},
   "source": [
    "## 2-4. 시각화(Matplotlib)를 통한 데이터 분포 분석\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e65df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 한글 폰트 설정 (필요시)\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'  # Windows\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 샘플 데이터 생성\n",
    "np.random.seed(42)\n",
    "data = {\n",
    "    '나이': np.random.normal(30, 5, 100),\n",
    "    '급여': np.random.normal(5000, 1000, 100),\n",
    "    '부서': np.random.choice(['개발팀', '디자인팀', '마케팅팀'], 100)\n",
    "}\n",
    "df_viz = pd.DataFrame(data)\n",
    "\n",
    "# 1. 히스토그램\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.hist(df_viz['나이'], bins=20, edgecolor='black')\n",
    "plt.title('나이 분포')\n",
    "plt.xlabel('나이')\n",
    "plt.ylabel('빈도')\n",
    "\n",
    "# 2. 박스플롯\n",
    "plt.subplot(1, 3, 2)\n",
    "df_viz.boxplot(column='급여', by='부서', ax=plt.gca())\n",
    "plt.title('부서별 급여 분포')\n",
    "plt.suptitle('')  # 기본 제목 제거\n",
    "\n",
    "# 3. 산점도\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.scatter(df_viz['나이'], df_viz['급여'], alpha=0.6)\n",
    "plt.title('나이 vs 급여')\n",
    "plt.xlabel('나이')\n",
    "plt.ylabel('급여')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a179753b",
   "metadata": {},
   "source": [
    "## 2-5. 특성 추출(Feature Engineering)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8c19cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특성 추출 예제 데이터\n",
    "df_feature = pd.DataFrame({\n",
    "    '날짜': pd.date_range('2023-01-01', periods=100, freq='D'),\n",
    "    '매출': np.random.normal(1000, 200, 100),\n",
    "    '카테고리': np.random.choice(['A', 'B', 'C'], 100)\n",
    "})\n",
    "\n",
    "print(\"원본 데이터:\")\n",
    "print(df_feature.head())\n",
    "\n",
    "# 1. 날짜 특성 추출\n",
    "df_feature['년'] = df_feature['날짜'].dt.year\n",
    "df_feature['월'] = df_feature['날짜'].dt.month\n",
    "df_feature['요일'] = df_feature['날짜'].dt.dayofweek\n",
    "df_feature['주말여부'] = df_feature['요일'].isin([5, 6]).astype(int)\n",
    "\n",
    "# 2. 범주형 변수 인코딩 (One-Hot Encoding)\n",
    "df_encoded = pd.get_dummies(df_feature, columns=['카테고리'], prefix='카테고리')\n",
    "\n",
    "# 3. 수치형 특성 변환\n",
    "df_feature['매출_로그'] = np.log1p(df_feature['매출'])\n",
    "df_feature['매출_정규화'] = (df_feature['매출'] - df_feature['매출'].mean()) / df_feature['매출'].std()\n",
    "\n",
    "print(\"\\n특성 추출 후:\")\n",
    "print(df_feature[['날짜', '매출', '년', '월', '요일', '주말여부', '매출_로그', '매출_정규화']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a8e0ec",
   "metadata": {},
   "source": [
    "## 2-6. 데이터 정제 자동화 스크립트 (산출물)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0186bd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    \"\"\"\n",
    "    데이터 정제 자동화 함수\n",
    "    - 결측치 처리\n",
    "    - 이상치 제거\n",
    "    - 데이터 타입 변환\n",
    "    \"\"\"\n",
    "    df_cleaned = df.copy()\n",
    "    \n",
    "    # 1. 결측치 처리 (수치형: 평균, 범주형: 최빈값)\n",
    "    for col in df_cleaned.columns:\n",
    "        if df_cleaned[col].dtype in ['int64', 'float64']:\n",
    "            df_cleaned[col].fillna(df_cleaned[col].mean(), inplace=True)\n",
    "        else:\n",
    "            df_cleaned[col].fillna(df_cleaned[col].mode()[0] if len(df_cleaned[col].mode()) > 0 else 'Unknown', inplace=True)\n",
    "    \n",
    "    # 2. 이상치 제거 (IQR 방법)\n",
    "    numeric_cols = df_cleaned.select_dtypes(include=[np.number]).columns\n",
    "    for col in numeric_cols:\n",
    "        Q1 = df_cleaned[col].quantile(0.25)\n",
    "        Q3 = df_cleaned[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        df_cleaned = df_cleaned[(df_cleaned[col] >= lower_bound) & (df_cleaned[col] <= upper_bound)]\n",
    "    \n",
    "    return df_cleaned\n",
    "\n",
    "# 테스트 데이터\n",
    "test_data = pd.DataFrame({\n",
    "    '나이': [25, 30, None, 35, 150, 28],  # 이상치: 150\n",
    "    '급여': [5000, None, 6000, 7000, 5000, 100000],  # 이상치: 100000\n",
    "    '부서': ['개발팀', '디자인팀', None, '개발팀', '마케팅팀', '개발팀']\n",
    "})\n",
    "\n",
    "print(\"정제 전:\")\n",
    "print(test_data)\n",
    "print(\"\\n결측치 개수:\")\n",
    "print(test_data.isnull().sum())\n",
    "\n",
    "df_cleaned = clean_data(test_data)\n",
    "\n",
    "print(\"\\n정제 후:\")\n",
    "print(df_cleaned)\n",
    "print(\"\\n정제 후 결측치 개수:\")\n",
    "print(df_cleaned.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f67dc1",
   "metadata": {},
   "source": [
    "# 3일차: Scikit-Learn 기초\n",
    "\n",
    "## 학습 내용\n",
    "- 선형 회귀의 수학적 원리 및 코드 구현\n",
    "- 로지스틱 회귀의 수학적 원리 및 코드 구현\n",
    "- Scikit-Learn을 이용한 모델 학습\n",
    "- 과적합 방지\n",
    "- 교차 검증(Cross-Validation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ef3723",
   "metadata": {},
   "source": [
    "## 3-1. 선형 회귀 (Linear Regression)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2c241b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 샘플 데이터 생성\n",
    "np.random.seed(42)\n",
    "X = np.random.rand(100, 1) * 10\n",
    "y = 2.5 * X.flatten() + 1.5 + np.random.randn(100) * 2\n",
    "\n",
    "# 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 선형 회귀 모델 학습\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "# 평가\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"회귀 계수: {lr.coef_[0]:.2f}\")\n",
    "print(f\"절편: {lr.intercept_:.2f}\")\n",
    "print(f\"평균 제곱 오차 (MSE): {mse:.2f}\")\n",
    "print(f\"결정 계수 (R²): {r2:.4f}\")\n",
    "\n",
    "# 시각화\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(X_test, y_test, alpha=0.6, label='실제값')\n",
    "plt.plot(X_test, y_pred, 'r-', label='예측값')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.title('선형 회귀 결과')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff298a6d",
   "metadata": {},
   "source": [
    "## 3-2. 로지스틱 회귀 (Logistic Regression)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929f1508",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# 샘플 데이터 생성\n",
    "X, y = make_classification(n_samples=200, n_features=2, n_redundant=0, \n",
    "                          n_informative=2, random_state=42, n_clusters_per_class=1)\n",
    "\n",
    "# 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 로지스틱 회귀 모델 학습\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = log_reg.predict(X_test)\n",
    "y_pred_proba = log_reg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# 평가\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"정확도: {accuracy:.4f}\")\n",
    "print(\"\\n혼동 행렬:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\n분류 보고서:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 시각화\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap='coolwarm', alpha=0.6, label='실제값')\n",
    "plt.xlabel('특성 1')\n",
    "plt.ylabel('특성 2')\n",
    "plt.title('로지스틱 회귀 분류 결과')\n",
    "plt.colorbar()\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ba1fbe",
   "metadata": {},
   "source": [
    "## 3-3. 과적합 방지 (Regularization)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf3a7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# 과적합을 보여주기 위한 데이터 생성\n",
    "np.random.seed(42)\n",
    "X = np.linspace(0, 10, 20).reshape(-1, 1)\n",
    "y = np.sin(X.flatten()) + np.random.randn(20) * 0.3\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 1. 일반 선형 회귀 (과적합 가능)\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr_train_score = lr.score(X_train, y_train)\n",
    "lr_test_score = lr.score(X_test, y_test)\n",
    "\n",
    "# 2. Ridge 회귀 (L2 정규화)\n",
    "ridge = Ridge(alpha=1.0)\n",
    "ridge.fit(X_train, y_train)\n",
    "ridge_train_score = ridge.score(X_train, y_train)\n",
    "ridge_test_score = ridge.score(X_test, y_test)\n",
    "\n",
    "# 3. Lasso 회귀 (L1 정규화)\n",
    "lasso = Lasso(alpha=0.1)\n",
    "lasso.fit(X_train, y_train)\n",
    "lasso_train_score = lasso.score(X_train, y_train)\n",
    "lasso_test_score = lasso.score(X_test, y_test)\n",
    "\n",
    "print(\"=== 모델 성능 비교 ===\")\n",
    "print(f\"일반 선형 회귀 - Train: {lr_train_score:.4f}, Test: {lr_test_score:.4f}\")\n",
    "print(f\"Ridge 회귀 - Train: {ridge_train_score:.4f}, Test: {ridge_test_score:.4f}\")\n",
    "print(f\"Lasso 회귀 - Train: {lasso_train_score:.4f}, Test: {lasso_test_score:.4f}\")\n",
    "\n",
    "# 시각화\n",
    "X_plot = np.linspace(0, 10, 100).reshape(-1, 1)\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.scatter(X_train, y_train, label='Train', alpha=0.6)\n",
    "plt.scatter(X_test, y_test, label='Test', alpha=0.6)\n",
    "plt.plot(X_plot, lr.predict(X_plot), label='Linear', linestyle='--')\n",
    "plt.plot(X_plot, ridge.predict(X_plot), label='Ridge', linestyle='-.')\n",
    "plt.plot(X_plot, lasso.predict(X_plot), label='Lasso', linestyle=':')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.title('과적합 방지 비교')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40067432",
   "metadata": {},
   "source": [
    "## 3-4. 교차 검증 (Cross-Validation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2582c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# 데이터 로드\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# 1. K-Fold 교차 검증\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "lr = LogisticRegression(max_iter=200)\n",
    "cv_scores = cross_val_score(lr, X, y, cv=kfold, scoring='accuracy')\n",
    "\n",
    "print(\"=== K-Fold 교차 검증 (5-fold) ===\")\n",
    "print(f\"각 fold의 정확도: {cv_scores}\")\n",
    "print(f\"평균 정확도: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "\n",
    "# 2. Stratified K-Fold (분류 문제에 적합)\n",
    "skfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores_stratified = cross_val_score(lr, X, y, cv=skfold, scoring='accuracy')\n",
    "\n",
    "print(\"\\n=== Stratified K-Fold 교차 검증 (5-fold) ===\")\n",
    "print(f\"각 fold의 정확도: {cv_scores_stratified}\")\n",
    "print(f\"평균 정확도: {cv_scores_stratified.mean():.4f} (+/- {cv_scores_stratified.std() * 2:.4f})\")\n",
    "\n",
    "# 3. 다양한 평가 지표로 교차 검증\n",
    "scoring_metrics = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']\n",
    "print(\"\\n=== 다양한 평가 지표 ===\")\n",
    "for metric in scoring_metrics:\n",
    "    scores = cross_val_score(lr, X, y, cv=5, scoring=metric)\n",
    "    print(f\"{metric}: {scores.mean():.4f} (+/- {scores.std() * 2:.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cc9731",
   "metadata": {},
   "source": [
    "## 3-5. 타이타닉 생존자 예측 모델 (산출물)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e492f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타이타닉 데이터셋 시뮬레이션 (실제 데이터가 없는 경우)\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "\n",
    "# 특성 생성\n",
    "titanic_data = pd.DataFrame({\n",
    "    '나이': np.random.randint(1, 80, n_samples),\n",
    "    '성별': np.random.choice([0, 1], n_samples),  # 0: 여성, 1: 남성\n",
    "    '객실등급': np.random.choice([1, 2, 3], n_samples),\n",
    "    '형제자매수': np.random.randint(0, 5, n_samples),\n",
    "    '부모자식수': np.random.randint(0, 5, n_samples),\n",
    "    '요금': np.random.normal(30, 15, n_samples)\n",
    "})\n",
    "\n",
    "# 생존 여부 생성 (여성, 어린이, 1등급 승객이 생존 확률 높음)\n",
    "survival_prob = (\n",
    "    0.7 * (titanic_data['성별'] == 0) +  # 여성\n",
    "    0.3 * (titanic_data['나이'] < 18) +  # 어린이\n",
    "    0.2 * (titanic_data['객실등급'] == 1) +  # 1등급\n",
    "    0.1 * np.random.rand(n_samples)\n",
    ")\n",
    "titanic_data['생존'] = (survival_prob > 0.5).astype(int)\n",
    "\n",
    "# 특성 엔지니어링\n",
    "titanic_data['가족수'] = titanic_data['형제자매수'] + titanic_data['부모자식수']\n",
    "titanic_data['어린이여부'] = (titanic_data['나이'] < 18).astype(int)\n",
    "\n",
    "# 특성 선택\n",
    "features = ['나이', '성별', '객실등급', '요금', '가족수', '어린이여부']\n",
    "X = titanic_data[features]\n",
    "y = titanic_data['생존']\n",
    "\n",
    "# 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 로지스틱 회귀 모델 학습\n",
    "titanic_model = LogisticRegression(max_iter=1000)\n",
    "titanic_model.fit(X_train, y_train)\n",
    "\n",
    "# 예측 및 평가\n",
    "y_pred = titanic_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"=== 타이타닉 생존자 예측 모델 ===\")\n",
    "print(f\"정확도: {accuracy:.4f}\")\n",
    "print(\"\\n혼동 행렬:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\n분류 보고서:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 교차 검증\n",
    "cv_scores = cross_val_score(titanic_model, X, y, cv=5, scoring='accuracy')\n",
    "print(f\"\\n교차 검증 평균 정확도: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "\n",
    "# 특성 중요도\n",
    "print(\"\\n=== 특성 중요도 (계수) ===\")\n",
    "feature_importance = pd.DataFrame({\n",
    "    '특성': features,\n",
    "    '계수': titanic_model.coef_[0]\n",
    "})\n",
    "feature_importance = feature_importance.sort_values('계수', key=abs, ascending=False)\n",
    "print(feature_importance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03bf5d5",
   "metadata": {},
   "source": [
    "# 4일차: Scikit-Learn 심화\n",
    "\n",
    "## 학습 내용\n",
    "- 결정 트리(Decision Tree)\n",
    "- 랜덤 포레스트 등 앙상블 기법\n",
    "- 하이퍼파라미터 튜닝(GridSearch)\n",
    "- 성능 평가 지표(F1, AUC) 마스터\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de43424f",
   "metadata": {},
   "source": [
    "## 4-1. 결정 트리 (Decision Tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264146c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# 샘플 데이터 생성\n",
    "X, y = make_classification(n_samples=200, n_features=2, n_redundant=0, \n",
    "                          n_informative=2, random_state=42, n_clusters_per_class=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 결정 트리 모델 학습\n",
    "dt = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# 예측 및 평가\n",
    "y_pred = dt.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"=== 결정 트리 모델 ===\")\n",
    "print(f\"정확도: {accuracy:.4f}\")\n",
    "print(f\"트리 깊이: {dt.get_depth()}\")\n",
    "print(f\"리프 노드 수: {dt.get_n_leaves()}\")\n",
    "\n",
    "# 특성 중요도\n",
    "print(\"\\n특성 중요도:\")\n",
    "for i, importance in enumerate(dt.feature_importances_):\n",
    "    print(f\"특성 {i}: {importance:.4f}\")\n",
    "\n",
    "# 시각화\n",
    "plt.figure(figsize=(15, 10))\n",
    "plot_tree(dt, filled=True, feature_names=['특성1', '특성2'], class_names=['클래스0', '클래스1'])\n",
    "plt.title('결정 트리 구조')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e651f886",
   "metadata": {},
   "source": [
    "## 4-2. 랜덤 포레스트 (Random Forest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5dd3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "# 랜덤 포레스트 모델 학습\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# 예측 및 평가\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "print(\"=== 랜덤 포레스트 모델 ===\")\n",
    "print(f\"정확도: {accuracy_rf:.4f}\")\n",
    "print(f\"트리 개수: {rf.n_estimators}\")\n",
    "\n",
    "# 특성 중요도\n",
    "print(\"\\n특성 중요도:\")\n",
    "for i, importance in enumerate(rf.feature_importances_):\n",
    "    print(f\"특성 {i}: {importance:.4f}\")\n",
    "\n",
    "# 결정 트리 vs 랜덤 포레스트 비교\n",
    "print(\"\\n=== 모델 비교 ===\")\n",
    "print(f\"결정 트리 정확도: {accuracy:.4f}\")\n",
    "print(f\"랜덤 포레스트 정확도: {accuracy_rf:.4f}\")\n",
    "\n",
    "# 시각화\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# 결정 트리 결정 경계\n",
    "ax = axes[0]\n",
    "h = 0.02\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "Z = dt.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "ax.contourf(xx, yy, Z, alpha=0.4, cmap='coolwarm')\n",
    "ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap='coolwarm', edgecolors='k')\n",
    "ax.set_title('결정 트리')\n",
    "ax.set_xlabel('특성 1')\n",
    "ax.set_ylabel('특성 2')\n",
    "\n",
    "# 랜덤 포레스트 결정 경계\n",
    "ax = axes[1]\n",
    "Z = rf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "ax.contourf(xx, yy, Z, alpha=0.4, cmap='coolwarm')\n",
    "ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap='coolwarm', edgecolors='k')\n",
    "ax.set_title('랜덤 포레스트')\n",
    "ax.set_xlabel('특성 1')\n",
    "ax.set_ylabel('특성 2')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bf3499",
   "metadata": {},
   "source": [
    "## 4-3. 그라디언트 부스팅 (Gradient Boosting)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0e3471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그라디언트 부스팅 모델 학습\n",
    "gb = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "# 예측 및 평가\n",
    "y_pred_gb = gb.predict(X_test)\n",
    "accuracy_gb = accuracy_score(y_test, y_pred_gb)\n",
    "\n",
    "print(\"=== 그라디언트 부스팅 모델 ===\")\n",
    "print(f\"정확도: {accuracy_gb:.4f}\")\n",
    "print(f\"부스팅 단계 수: {gb.n_estimators}\")\n",
    "\n",
    "# 학습 곡선 시각화\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for i, y_pred_train in enumerate(gb.staged_predict(X_train)):\n",
    "    train_scores.append(accuracy_score(y_train, y_pred_train))\n",
    "\n",
    "for i, y_pred_test in enumerate(gb.staged_predict(X_test)):\n",
    "    test_scores.append(accuracy_score(y_test, y_pred_test))\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, len(train_scores) + 1), train_scores, label='Train', alpha=0.7)\n",
    "plt.plot(range(1, len(test_scores) + 1), test_scores, label='Test', alpha=0.7)\n",
    "plt.xlabel('부스팅 단계')\n",
    "plt.ylabel('정확도')\n",
    "plt.title('그라디언트 부스팅 학습 곡선')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n=== 앙상블 모델 비교 ===\")\n",
    "print(f\"결정 트리: {accuracy:.4f}\")\n",
    "print(f\"랜덤 포레스트: {accuracy_rf:.4f}\")\n",
    "print(f\"그라디언트 부스팅: {accuracy_gb:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7acbb68",
   "metadata": {},
   "source": [
    "## 4-4. 하이퍼파라미터 튜닝 (GridSearch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed4702d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 그리드 서치를 위한 파라미터 그리드 정의\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# 랜덤 포레스트 그리드 서치\n",
    "rf_grid = RandomForestClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(rf_grid, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"=== 그리드 서치 결과 ===\")\n",
    "print(f\"최적 파라미터: {grid_search.best_params_}\")\n",
    "print(f\"최적 교차 검증 점수: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# 최적 모델로 예측\n",
    "best_rf = grid_search.best_estimator_\n",
    "y_pred_best = best_rf.predict(X_test)\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "\n",
    "print(f\"테스트 세트 정확도: {accuracy_best:.4f}\")\n",
    "\n",
    "# 결과 비교\n",
    "print(\"\\n=== 튜닝 전후 비교 ===\")\n",
    "print(f\"튜닝 전 랜덤 포레스트: {accuracy_rf:.4f}\")\n",
    "print(f\"튜닝 후 랜덤 포레스트: {accuracy_best:.4f}\")\n",
    "\n",
    "# 결과 시각화\n",
    "results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "print(\"\\n상위 5개 파라미터 조합:\")\n",
    "top_results = results_df.nlargest(5, 'mean_test_score')[['params', 'mean_test_score', 'std_test_score']]\n",
    "for idx, row in top_results.iterrows():\n",
    "    print(f\"파라미터: {row['params']}, 점수: {row['mean_test_score']:.4f} (+/- {row['std_test_score']*2:.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673d6134",
   "metadata": {},
   "source": [
    "## 4-5. 성능 평가 지표 (F1, AUC 등)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab4962e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (f1_score, roc_auc_score, roc_curve, \n",
    "                            precision_score, recall_score, precision_recall_curve)\n",
    "\n",
    "# 여러 모델의 예측 확률 계산\n",
    "dt_proba = dt.predict_proba(X_test)[:, 1]\n",
    "rf_proba = rf.predict_proba(X_test)[:, 1]\n",
    "gb_proba = gb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# 평가 지표 계산\n",
    "models = {\n",
    "    '결정 트리': (y_pred, dt_proba),\n",
    "    '랜덤 포레스트': (y_pred_rf, rf_proba),\n",
    "    '그라디언트 부스팅': (y_pred_gb, gb_proba)\n",
    "}\n",
    "\n",
    "print(\"=== 성능 평가 지표 비교 ===\")\n",
    "print(f\"{'모델':<20} {'정확도':<10} {'정밀도':<10} {'재현율':<10} {'F1':<10} {'AUC':<10}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for name, (y_pred_model, y_proba) in models.items():\n",
    "    accuracy = accuracy_score(y_test, y_pred_model)\n",
    "    precision = precision_score(y_test, y_pred_model)\n",
    "    recall = recall_score(y_test, y_pred_model)\n",
    "    f1 = f1_score(y_test, y_pred_model)\n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "    \n",
    "    print(f\"{name:<20} {accuracy:<10.4f} {precision:<10.4f} {recall:<10.4f} {f1:<10.4f} {auc:<10.4f}\")\n",
    "\n",
    "# ROC 곡선 시각화\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# ROC 곡선\n",
    "plt.subplot(1, 2, 1)\n",
    "for name, (_, y_proba) in models.items():\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "    auc_score = roc_auc_score(y_test, y_proba)\n",
    "    plt.plot(fpr, tpr, label=f'{name} (AUC={auc_score:.3f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='랜덤 분류기')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC 곡선')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Precision-Recall 곡선\n",
    "plt.subplot(1, 2, 2)\n",
    "for name, (_, y_proba) in models.items():\n",
    "    precision_curve, recall_curve, _ = precision_recall_curve(y_test, y_proba)\n",
    "    plt.plot(recall_curve, precision_curve, label=name)\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall 곡선')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38984d28",
   "metadata": {},
   "source": [
    "## 4-6. 고성능 분류 예측기 (산출물)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084eaf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# 앙상블 모델 생성 (Voting Classifier)\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('dt', DecisionTreeClassifier(max_depth=5, random_state=42)),\n",
    "        ('rf', RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)),\n",
    "        ('gb', GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42))\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# 모델 학습\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred_voting = voting_clf.predict(X_test)\n",
    "y_proba_voting = voting_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# 평가\n",
    "accuracy_voting = accuracy_score(y_test, y_pred_voting)\n",
    "f1_voting = f1_score(y_test, y_pred_voting)\n",
    "auc_voting = roc_auc_score(y_test, y_proba_voting)\n",
    "\n",
    "print(\"=== 고성능 앙상블 분류 예측기 ===\")\n",
    "print(f\"정확도: {accuracy_voting:.4f}\")\n",
    "print(f\"F1 점수: {f1_voting:.4f}\")\n",
    "print(f\"AUC 점수: {auc_voting:.4f}\")\n",
    "\n",
    "# 교차 검증으로 성능 평가\n",
    "scoring = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro', 'roc_auc']\n",
    "cv_results = cross_validate(voting_clf, X, y, cv=5, scoring=scoring, return_train_score=True)\n",
    "\n",
    "print(\"\\n=== 5-Fold 교차 검증 결과 ===\")\n",
    "for metric in scoring:\n",
    "    test_scores = cv_results[f'test_{metric}']\n",
    "    print(f\"{metric}: {test_scores.mean():.4f} (+/- {test_scores.std() * 2:.4f})\")\n",
    "\n",
    "# 개별 모델과 비교\n",
    "print(\"\\n=== 개별 모델 vs 앙상블 비교 ===\")\n",
    "print(f\"결정 트리: {accuracy:.4f}\")\n",
    "print(f\"랜덤 포레스트: {accuracy_rf:.4f}\")\n",
    "print(f\"그라디언트 부스팅: {accuracy_gb:.4f}\")\n",
    "print(f\"Voting 앙상블: {accuracy_voting:.4f}\")\n",
    "\n",
    "# 최종 모델 저장 (pickle 사용 예시)\n",
    "import pickle\n",
    "print(\"\\n모델이 학습되었습니다. 필요시 pickle로 저장할 수 있습니다:\")\n",
    "print(\"with open('best_classifier.pkl', 'wb') as f:\")\n",
    "print(\"    pickle.dump(voting_clf, f)\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
