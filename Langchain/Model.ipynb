{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1c3b99f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========== LangChain 1.0 RAG 에이전트 실습 (문법 위주) ==========\n",
        "# 필요한 패키지: pip install langchain langchain-text-splitters langchain-community langchain-openai langchain-core bs4\n",
        "\n",
        "# --- 1) 모델 초기화 (문법: init_chat_model) ---\n",
        "import os\n",
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "# 환경변수 OPENAI_API_KEY 또는 ANTHROPIC_API_KEY 필요\n",
        "model = init_chat_model(\"gpt-4o-mini\")  # OpenAI. 또는 \"gpt-4.1\"\n",
        "# model = init_chat_model(\"claude-sonnet-4-5-20250929\")  # Anthropic"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25f81e10",
      "metadata": {},
      "source": [
        "## RAG 플로우 요약\n",
        "1. **인덱싱**: 문서 로드 → 청크 분할 → 벡터 스토어 저장  \n",
        "2. **검색·생성**: 리트리버 도구로 검색 → 에이전트가 도구 호출 후 답변 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45552710",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- 2) 임베딩 + 벡터 스토어 (문법) ---\n",
        "# pip install langchain-openai\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_core.vectorstores import InMemoryVectorStore\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")  # 또는 text-embedding-3-large\n",
        "vector_store = InMemoryVectorStore(embeddings)  # 메모리 저장소 (실무는 Chroma, FAISS 등)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "def84408",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- 3) 문서 로드 (문법: DocumentLoader) ---\n",
        "# langchain_community.document_loaders: WebBaseLoader, PyPDFLoader, TextLoader 등\n",
        "import bs4\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "\n",
        "# 웹 URL → Document 리스트. bs_kwargs로 파싱 영역 제한 가능\n",
        "loader = WebBaseLoader(\n",
        "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
        "    bs_kwargs=dict(parse_only=bs4.SoupStrainer(class_=(\"post-content\", \"post-title\", \"post-header\"))),\n",
        ")\n",
        "docs = loader.load()  # list[Document], 각 Document는 page_content + metadata\n",
        "print(f\"로드된 문서 수: {len(docs)}, 첫 문서 길이: {len(docs[0].page_content)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27e71661",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- 4) 문서 분할 (문법: TextSplitter) ---\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,      # 청크 최대 문자 수\n",
        "    chunk_overlap=200,     # 청크 간 겹침\n",
        "    add_start_index=True,  # 원본 내 위치 메타데이터\n",
        ")\n",
        "all_splits = text_splitter.split_documents(docs)  # list[Document]\n",
        "print(f\"총 {len(all_splits)}개 청크로 분할\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4789e9ce",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- 5) 벡터 스토어에 저장 (인덱싱 완료) ---\n",
        "# add_documents: 임베딩 후 저장, document_ids 반환\n",
        "document_ids = vector_store.add_documents(documents=all_splits)\n",
        "print(\"인덱싱 완료. ID 샘플:\", document_ids[:3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec7cdeb2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- 6) RAG용 도구 정의 (문법: @tool) ---\n",
        "# 에이전트가 \"검색\"을 할 때 이 함수가 호출됨\n",
        "from langchain.tools import tool\n",
        "\n",
        "@tool(response_format=\"content_and_artifact\")  # 문자열 + 원본 문서를 artifact로 반환\n",
        "def retrieve_context(query: str):\n",
        "    \"\"\"Retrieve information to help answer a query. 쿼리에 맞는 문서를 검색합니다.\"\"\"\n",
        "    retrieved_docs = vector_store.similarity_search(query, k=2)  # 상위 k개 유사 문서\n",
        "    serialized = \"\\n\\n\".join(\n",
        "        f\"Source: {doc.metadata}\\nContent: {doc.page_content}\" for doc in retrieved_docs\n",
        "    )\n",
        "    return serialized, retrieved_docs  # (모델에 줄 텍스트, 앱에서 쓸 문서 리스트)\n",
        "\n",
        "tools = [retrieve_context]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71dde09e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- 7) 에이전트 생성 (문법: create_agent) ---\n",
        "from langchain.agents import create_agent\n",
        "\n",
        "# create_agent(model, tools, system_prompt=...)  ← 1.0 스타일\n",
        "system_prompt = (\n",
        "    \"You have access to a tool that retrieves context from a blog post. \"\n",
        "    \"Use the tool to help answer user queries.\"\n",
        ")\n",
        "agent = create_agent(model, tools, system_prompt=system_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cfbb668",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- 8) 실행: invoke (한 번에 결과) ---\n",
        "# 입력 형식: {\"messages\": [{\"role\": \"user\", \"content\": \"질문\"}]}\n",
        "query = \"What is task decomposition?\"\n",
        "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": query}]})\n",
        "# result[\"messages\"][-1] 이 최종 AI 응답\n",
        "print(result[\"messages\"][-1].content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02f035f8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- 9) 실행: stream (단계별 스트리밍) ---\n",
        "# stream_mode=\"values\": 매 단계마다 전체 state 스냅샷\n",
        "for step in agent.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": query}]},\n",
        "    stream_mode=\"values\",\n",
        "):\n",
        "    step[\"messages\"][-1].pretty_print()  # 툴 호출 → 툴 결과 → 최종 답변 순으로 출력"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6d3c27b",
      "metadata": {},
      "source": [
        "### 문법 요약 (LangChain 1.0)\n",
        "| 단계 | 문법 |\n",
        "|------|------|\n",
        "| 모델 | `init_chat_model(\"gpt-4o-mini\")` from `langchain.chat_models` |\n",
        "| 임베딩 | `OpenAIEmbeddings()` from `langchain_openai` |\n",
        "| 벡터스토어 | `InMemoryVectorStore(embeddings)` from `langchain_core.vectorstores` |\n",
        "| 로더 | `WebBaseLoader(web_paths=(url,)).load()` from `langchain_community.document_loaders` |\n",
        "| 분할 | `RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200).split_documents(docs)` |\n",
        "| 저장 | `vector_store.add_documents(documents=all_splits)` |\n",
        "| 도구 | `@tool(response_format=\"content_and_artifact\")` def fn(query: str): ... from `langchain.tools` |\n",
        "| 에이전트 | `create_agent(model, tools, system_prompt=...)` from `langchain.agents` |\n",
        "| 실행 | `agent.invoke({\"messages\": [{\"role\":\"user\",\"content\": query}]})` 또는 `agent.stream(..., stream_mode=\"values\")` |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "899e9c24",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
